{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Model v0\n",
    "\n",
    "Model v0 is an ML model for typical V-NLI, which accepts text and tabular data as input, and returns the corresponding figure.\n",
    "\n",
    "We adopt [TAPEX](https://arxiv.org/abs/2107.07653), a pre-trained [BART](https://arxiv.org/abs/1910.13461) model, as a base model.\n",
    "And we use almost the same hyperparameters as TAPEX.\n",
    "\n",
    "We fine-tune the model with the two nvBench datasets preprocessed in the previous notebook.\n",
    "One model is for the user study, and another is for real-world usage (Check the details in the previous notebook).\n",
    "\n",
    "We use Hugging Face Transformers, one of the most famous NLP libraries, for implementation.\n",
    "Primarily we refer to [this TAPEX example](https://github.com/huggingface/transformers/blob/main/examples/research_projects/tapex/run_wikisql_with_tapex.py\n",
    ").\n",
    "\n",
    "As a result, the exact match ratio of the user study model gets to be ~90% for the test dataset, and the model for real-world usage gets to be ~60%.\n",
    "It's not comparable to the existing work because we adopt a different way to preprocess the nvBench dataset.\n",
    "However, our goal is not to improve an ML model for V-NLI but to propose a novel UI for data visualization.\n",
    "\n",
    "In the final user study, we use this model as the baseline model to compare our proposed interface with typical V-NLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/\"\n",
    "load_model_from_last_checkpoint: bool = False\n",
    "push_model_to_huggingface_hub: bool = True\n",
    "skip_training: bool = False\n",
    "\n",
    "# If user_study is True, the model is trained by the preprocessed dataset with the stratified sampling\n",
    "# Otherwise, the group shuffled dataset is used\n",
    "# See the preprocess notebook for the details of the datasets\n",
    "user_study: bool = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BartConfig,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    EvalPrediction,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TapexTokenizer,\n",
    "    trainer_utils,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.set_seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATA_DIR: Path = Path(data_dir)\n",
    "DATABASE_DIR: Path = DATA_DIR.joinpath(\"database\")\n",
    "\n",
    "if user_study:\n",
    "    MODEL_NAME: str = \"vxnli-v0-user-study\"\n",
    "    PREPROCESSED_NVBENCH_DIR: Path = DATA_DIR.joinpath(\n",
    "        \"preprocessed-nvBench/stratified\"\n",
    "    )\n",
    "else:\n",
    "    MODEL_NAME: str = \"vxnli-v0\"\n",
    "    PREPROCESSED_NVBENCH_DIR: Path = DATA_DIR.joinpath(\"preprocessed-nvBench/grouped\")\n",
    "\n",
    "DATASET_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"{MODEL_NAME}.hf\")\n",
    "MODEL_OUTPUT_DIR: Path = DATA_DIR.joinpath(MODEL_NAME)\n",
    "PREDS_OUTPUT_PATH: Path = DATA_DIR.joinpath(f\"{MODEL_NAME}-preds.csv\")\n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "BASE_MODEL: str = \"microsoft/tapex-base-finetuned-wtq\"\n",
    "MAX_SOURCE_LENGTH: int = 1024\n",
    "MAX_TARGET_LENGTH: int = 124\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TapexTokenizer.from_pretrained(\n",
    "    BASE_MODEL, use_fast=True, add_prefix_space=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 11311,  4832,  5552,  1721,   346,     9,  4133,  3236,   112,\n",
       "          4832,  5378,   625,   181,  2582,  1721,  8176,  3236,   132,  4832,\n",
       "          2084,   261,  6782,  2269,  2927, 12834,  1721,  4268,  3236,   155,\n",
       "          4832,  5473, 26875, 42771,  6071,  1721,  5913,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "tokenizer(\n",
    "    table=pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n",
    "            \"Number of movies\": [\"87\", \"53\", \"69\"],\n",
    "        }\n",
    "    ),\n",
    "    answer=\"how many movies does Leonardo Di Caprio have?\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BartConfig.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    no_repeat_ngram_size=0,\n",
    "    max_length=MAX_SOURCE_LENGTH,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "if load_model_from_last_checkpoint:\n",
    "    model = trainer_utils.get_last_checkpoint(MODEL_OUTPUT_DIR)\n",
    "else:\n",
    "    model = BASE_MODEL\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    model,\n",
    "    config=model_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>5.475398e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>3.059093e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1.026885e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2.295667e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5.927022e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id product_type_code product_name  product_price\n",
       "0           1          Hardware        Apple   5.475398e+07\n",
       "1           2           Clothes        jcrew   3.059093e+07\n",
       "2           3          Hardware        Apple   1.026885e+04\n",
       "3           4          Hardware        Apple   2.295667e+07\n",
       "4           5           Clothes        jcrew   5.927022e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    db_path = DATABASE_DIR.joinpath(f\"{db_id}/{db_id}.sqlite\")\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        return pd.read_sql(f\"SELECT * FROM {table_name}\", con)\n",
    "\n",
    "\n",
    "# Example\n",
    "load_table(\"customers_and_products_contacts\", \"products\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>54753982.574522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>30590929.528306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>10268.85297069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>22956668.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5927021.8748021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_type_code product_name    product_price\n",
       "0          1          hardware        apple  54753982.574522\n",
       "1          2           clothes        jcrew  30590929.528306\n",
       "2          3          hardware        apple   10268.85297069\n",
       "3          4          hardware        apple  22956668.699482\n",
       "4          5           clothes        jcrew  5927021.8748021"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={col: col.lower() for col in df.columns})\n",
    "\n",
    "    # The TAPEX tokenizer raises an error when the table contains non-str columns\n",
    "    df = df.astype(str)\n",
    "\n",
    "    for col_name, col_dtype in zip(df.columns, df.dtypes):\n",
    "        df[col_name] = df[col_name].str.lower()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocess_table(load_table(\"customers_and_products_contacts\", \"products\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functools.cache is supported in python3.9+, but use lru_cache to support python3.7+\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_and_preprocess_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    table = load_table(db_id, table_name)\n",
    "    table = preprocess_table(table)\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    table = load_and_preprocess_table(example[\"db_id\"], example[\"table\"])\n",
    "\n",
    "    query = example[\"question\"]\n",
    "    answer = example[\"vega_zero\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        table=table,\n",
    "        query=query,\n",
    "        answer=answer,\n",
    "        max_length=MAX_SOURCE_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        answer=answer,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12798\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1543\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1385\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET_OUTPUT_DIR.exists():\n",
    "    # load_from_dist doesn't support pathlib.Path\n",
    "    dataset = datasets.load_from_disk(str(DATASET_OUTPUT_DIR))\n",
    "else:\n",
    "    dataset = datasets.load_dataset(\n",
    "        \"csv\",\n",
    "        data_files={\n",
    "            # load_dataset doesn't support pathlib.Path\n",
    "            \"train\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"train.csv\")),\n",
    "            \"test\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"test.csv\")),\n",
    "            \"validation\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"val.csv\")),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        preprocess_dataset,\n",
    "        batched=False,\n",
    "        num_proc=multiprocessing.cpu_count(),\n",
    "    )\n",
    "\n",
    "    # save_to_disk doesn't support pathlib.Path\n",
    "    dataset.save_to_disk(str(DATASET_OUTPUT_DIR))\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return exact_match.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface trainer uses environment variables to configure mlflow\n",
    "# https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/integrations.py#L884\n",
    "\n",
    "# MLFlow experiment name must be updated if you update training arguments\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = f\"{MODEL_NAME}-{datetime.now().strftime('%Y%m%d%H%M')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vxnli/notebooks/../data/vxnli-v0 is already a clone of https://huggingface.co/kwkty/vxnli-v0. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=Seq2SeqTrainingArguments(\n",
    "        output_dir=MODEL_OUTPUT_DIR,\n",
    "        predict_with_generate=True,\n",
    "        num_train_epochs=50,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=True,\n",
    "        metric_for_best_model=\"exact_match\",\n",
    "        push_to_hub=push_model_to_huggingface_hub,\n",
    "        report_to=\"mlflow\",\n",
    "    ),\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=5),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 12798\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40000\n",
      "  Number of trainable parameters = 139420416\n",
      "2022/11/30 09:28:14 INFO mlflow.tracking.fluent: Experiment with name 'vxnli-v0-202211300927' does not exist. Creating a new experiment.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14400' max='40000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14400/40000 1:59:17 < 3:32:05, 2.01 it/s, Epoch 18/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.398999</td>\n",
       "      <td>0.524188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.430023</td>\n",
       "      <td>0.574007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.498301</td>\n",
       "      <td>0.550181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>0.555235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.424967</td>\n",
       "      <td>0.580505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.481935</td>\n",
       "      <td>0.582671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.369306</td>\n",
       "      <td>0.566787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.554513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.488884</td>\n",
       "      <td>0.574007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.449606</td>\n",
       "      <td>0.590614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.535914</td>\n",
       "      <td>0.571119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.567509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.531721</td>\n",
       "      <td>0.543682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.599207</td>\n",
       "      <td>0.569675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.583093</td>\n",
       "      <td>0.511191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.606939</td>\n",
       "      <td>0.538628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.608627</td>\n",
       "      <td>0.552347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-800\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-800/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-800/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-1600\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-1600/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-1600/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-800] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-2400\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-2400/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-2400/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-3200\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-3200/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-3200/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-2400] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-4000\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-4000/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-4000/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-1600] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-3200] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-4800\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-4800/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-4800/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-4000] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-5600\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-5600/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-5600/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-5600/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-6400\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-6400/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-6400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-6400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-6400/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-5600] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-7200\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-7200/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-7200/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-6400] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-8000\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-8000/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-8000/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-4800] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-7200] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-8800\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-8800/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-8800/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-8800/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-8800/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-9600\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-9600/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-9600/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-8800] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-10400\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-10400/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-10400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-10400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-10400/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-8000] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-9600] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-11200\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-11200/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-11200/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-11200/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-11200/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-12000\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-12000/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-12000/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-11200] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-12800\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-12800/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-12800/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-12800/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-12800/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-12000] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-13600\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-13600/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-13600/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-13600/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-13600/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-12800] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1385\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../data/vxnli-v0/checkpoint-14400\n",
      "Configuration saved in ../data/vxnli-v0/checkpoint-14400/config.json\n",
      "Model weights saved in ../data/vxnli-v0/checkpoint-14400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/checkpoint-14400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/checkpoint-14400/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-13600] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/vxnli-v0/checkpoint-10400 (score: 0.5956678700361011).\n",
      "Deleting older checkpoint [../data/vxnli-v0/checkpoint-14400] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1543\n",
      "  Batch size = 16\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.33394524455070496,\n",
       " 'eval_exact_match': 0.609850939727803,\n",
       " 'eval_runtime': 115.3458,\n",
       " 'eval_samples_per_second': 13.377,\n",
       " 'eval_steps_per_second': 0.841,\n",
       " 'epoch': 18.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate must be called for the model card\n",
    "\n",
    "trainer.evaluate(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ds: Dataset) -> List[str]:\n",
    "    preds = trainer.predict(\n",
    "        ds,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "    )\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return [pred.strip() for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: vega_zero, query, table, hardness, question, SQL, chart, db_id. If vega_zero, query, table, hardness, question, SQL, chart, db_id are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1543\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['mark bar encoding x openning_year y aggregate count openning_year transform group x sort x desc',\n",
       "  'mark bar encoding x year y aggregate count year transform group x sort y desc',\n",
       "  'mark bar encoding x sex y aggregate min weight transform group x sort y desc',\n",
       "  'mark bar encoding x sex y aggregate mean weight transform group x sort y desc',\n",
       "  'mark bar encoding x date_address_from y aggregate count date_address_from transform bin x by month'],\n",
       " ['mark bar encoding x openning_year y aggregate count openning_year transform group x sort x desc',\n",
       "  'mark bar encoding x year y aggregate count year transform group x sort y desc',\n",
       "  'mark bar encoding x sex y aggregate min weight transform group x sort y desc',\n",
       "  'mark bar encoding x sex y aggregate mean weight transform group x sort y desc',\n",
       "  'mark bar encoding x date_address_from y aggregate count date_address_from transform sort monthly_rental desc bin x by year'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(dataset[\"test\"])\n",
    "\n",
    "preds[:5], dataset[\"test\"][\"vega_zero\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.6072585871678549}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match.compute(\n",
    "    predictions=preds,\n",
    "    references=dataset[\"test\"][\"vega_zero\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>SQL</th>\n",
       "      <th>table</th>\n",
       "      <th>pred</th>\n",
       "      <th>exact_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cinema</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Openning_year , COUNT(Ope...</td>\n",
       "      <td>give me a bar chart showing the number of cine...</td>\n",
       "      <td>mark bar encoding x openning_year y aggregate ...</td>\n",
       "      <td>SELECT Openning_year , COUNT(Openning_year) FR...</td>\n",
       "      <td>cinema</td>\n",
       "      <td>mark bar encoding x openning_year y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wta_1</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT year , count(*) FROM matc...</td>\n",
       "      <td>find the number of matches happened in each ye...</td>\n",
       "      <td>mark bar encoding x year y aggregate count yea...</td>\n",
       "      <td>SELECT year , count(*) FROM matches GROUP BY Y...</td>\n",
       "      <td>matches</td>\n",
       "      <td>mark bar encoding x year y aggregate count yea...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize BAR SELECT Sex , min(weight) FROM pe...</td>\n",
       "      <td>what is the minimum weights for people of each...</td>\n",
       "      <td>mark bar encoding x sex y aggregate min weight...</td>\n",
       "      <td>SELECT Sex , min(weight) FROM people GROUP BY ...</td>\n",
       "      <td>people</td>\n",
       "      <td>mark bar encoding x sex y aggregate min weight...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Sex , AVG(Weight) FROM pe...</td>\n",
       "      <td>show me the average of weight by sex in a hist...</td>\n",
       "      <td>mark bar encoding x sex y aggregate mean weigh...</td>\n",
       "      <td>SELECT Sex , AVG(Weight) FROM people GROUP BY ...</td>\n",
       "      <td>people</td>\n",
       "      <td>mark bar encoding x sex y aggregate mean weigh...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behavior_monitoring</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT date_address_from , COUNT...</td>\n",
       "      <td>visualize a bar chart about the distribution o...</td>\n",
       "      <td>mark bar encoding x date_address_from y aggreg...</td>\n",
       "      <td>SELECT date_address_from , COUNT(date_address_...</td>\n",
       "      <td>student_addresses</td>\n",
       "      <td>mark bar encoding x date_address_from y aggreg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>local_govt_in_alabama</td>\n",
       "      <td>Pie</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize PIE SELECT Event_Details , COUNT(Eve...</td>\n",
       "      <td>group and count details for the events using a...</td>\n",
       "      <td>mark arc encoding x event_details y aggregate ...</td>\n",
       "      <td>SELECT Event_Details , COUNT(Event_Details) FR...</td>\n",
       "      <td>events</td>\n",
       "      <td>mark arc encoding x event_details y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>riding_club</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Occupation , COUNT(Occupa...</td>\n",
       "      <td>bar chart x axis occupation y axis how many oc...</td>\n",
       "      <td>mark bar encoding x occupation y aggregate cou...</td>\n",
       "      <td>SELECT Occupation , COUNT(Occupation) FROM pla...</td>\n",
       "      <td>player</td>\n",
       "      <td>mark bar encoding x occupation y aggregate cou...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>store_product</td>\n",
       "      <td>Pie</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize PIE SELECT Type , count(*) FROM stor...</td>\n",
       "      <td>for each type of store , how many of them are ...</td>\n",
       "      <td>mark arc encoding x type y aggregate count typ...</td>\n",
       "      <td>SELECT Type , count(*) FROM store GROUP BY TYPE</td>\n",
       "      <td>store</td>\n",
       "      <td>mark arc encoding x type y aggregate count typ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize BAR SELECT Name , Weight FROM people...</td>\n",
       "      <td>return a bar chart about the distribution of n...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>SELECT Name , Weight FROM people ORDER BY Name...</td>\n",
       "      <td>people</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>behavior_monitoring</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT other_details , SUM(month...</td>\n",
       "      <td>return a bar chart about the distribution of o...</td>\n",
       "      <td>mark bar encoding x other_details y aggregate ...</td>\n",
       "      <td>SELECT other_details , SUM(monthly_rental) FRO...</td>\n",
       "      <td>student_addresses</td>\n",
       "      <td>mark bar encoding x other_details y aggregate ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1543 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      db_id chart hardness  \\\n",
       "0                    cinema   Bar   Medium   \n",
       "1                     wta_1   Bar   Medium   \n",
       "2            candidate_poll   Bar     Easy   \n",
       "3            candidate_poll   Bar   Medium   \n",
       "4       behavior_monitoring   Bar   Medium   \n",
       "...                     ...   ...      ...   \n",
       "1538  local_govt_in_alabama   Pie     Easy   \n",
       "1539            riding_club   Bar   Medium   \n",
       "1540          store_product   Pie     Easy   \n",
       "1541         candidate_poll   Bar     Easy   \n",
       "1542    behavior_monitoring   Bar   Medium   \n",
       "\n",
       "                                                  query  \\\n",
       "0     Visualize BAR SELECT Openning_year , COUNT(Ope...   \n",
       "1     Visualize BAR SELECT year , count(*) FROM matc...   \n",
       "2     Visualize BAR SELECT Sex , min(weight) FROM pe...   \n",
       "3     Visualize BAR SELECT Sex , AVG(Weight) FROM pe...   \n",
       "4     Visualize BAR SELECT date_address_from , COUNT...   \n",
       "...                                                 ...   \n",
       "1538  Visualize PIE SELECT Event_Details , COUNT(Eve...   \n",
       "1539  Visualize BAR SELECT Occupation , COUNT(Occupa...   \n",
       "1540  Visualize PIE SELECT Type , count(*) FROM stor...   \n",
       "1541  Visualize BAR SELECT Name , Weight FROM people...   \n",
       "1542  Visualize BAR SELECT other_details , SUM(month...   \n",
       "\n",
       "                                               question  \\\n",
       "0     give me a bar chart showing the number of cine...   \n",
       "1     find the number of matches happened in each ye...   \n",
       "2     what is the minimum weights for people of each...   \n",
       "3     show me the average of weight by sex in a hist...   \n",
       "4     visualize a bar chart about the distribution o...   \n",
       "...                                                 ...   \n",
       "1538  group and count details for the events using a...   \n",
       "1539  bar chart x axis occupation y axis how many oc...   \n",
       "1540  for each type of store , how many of them are ...   \n",
       "1541  return a bar chart about the distribution of n...   \n",
       "1542  return a bar chart about the distribution of o...   \n",
       "\n",
       "                                              vega_zero  \\\n",
       "0     mark bar encoding x openning_year y aggregate ...   \n",
       "1     mark bar encoding x year y aggregate count yea...   \n",
       "2     mark bar encoding x sex y aggregate min weight...   \n",
       "3     mark bar encoding x sex y aggregate mean weigh...   \n",
       "4     mark bar encoding x date_address_from y aggreg...   \n",
       "...                                                 ...   \n",
       "1538  mark arc encoding x event_details y aggregate ...   \n",
       "1539  mark bar encoding x occupation y aggregate cou...   \n",
       "1540  mark arc encoding x type y aggregate count typ...   \n",
       "1541  mark bar encoding x name y aggregate none weig...   \n",
       "1542  mark bar encoding x other_details y aggregate ...   \n",
       "\n",
       "                                                    SQL              table  \\\n",
       "0     SELECT Openning_year , COUNT(Openning_year) FR...             cinema   \n",
       "1     SELECT year , count(*) FROM matches GROUP BY Y...            matches   \n",
       "2     SELECT Sex , min(weight) FROM people GROUP BY ...             people   \n",
       "3     SELECT Sex , AVG(Weight) FROM people GROUP BY ...             people   \n",
       "4     SELECT date_address_from , COUNT(date_address_...  student_addresses   \n",
       "...                                                 ...                ...   \n",
       "1538  SELECT Event_Details , COUNT(Event_Details) FR...             events   \n",
       "1539  SELECT Occupation , COUNT(Occupation) FROM pla...             player   \n",
       "1540    SELECT Type , count(*) FROM store GROUP BY TYPE              store   \n",
       "1541  SELECT Name , Weight FROM people ORDER BY Name...             people   \n",
       "1542  SELECT other_details , SUM(monthly_rental) FRO...  student_addresses   \n",
       "\n",
       "                                                   pred  exact_matched  \n",
       "0     mark bar encoding x openning_year y aggregate ...           True  \n",
       "1     mark bar encoding x year y aggregate count yea...           True  \n",
       "2     mark bar encoding x sex y aggregate min weight...           True  \n",
       "3     mark bar encoding x sex y aggregate mean weigh...           True  \n",
       "4     mark bar encoding x date_address_from y aggreg...          False  \n",
       "...                                                 ...            ...  \n",
       "1538  mark arc encoding x event_details y aggregate ...           True  \n",
       "1539  mark bar encoding x occupation y aggregate cou...           True  \n",
       "1540  mark arc encoding x type y aggregate count typ...           True  \n",
       "1541  mark bar encoding x name y aggregate none weig...           True  \n",
       "1542  mark bar encoding x other_details y aggregate ...          False  \n",
       "\n",
       "[1543 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = dataset[\"test\"].to_pandas()\n",
    "preds_df = preds_df.drop(columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "preds_df[\"pred\"] = preds\n",
    "preds_df[\"exact_matched\"] = preds_df[\"pred\"] == preds_df[\"vega_zero\"]\n",
    "\n",
    "preds_df.to_csv(PREDS_OUTPUT_PATH)\n",
    "\n",
    "preds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easy</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Hard</th>\n",
       "      <th>Extra Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>422</td>\n",
       "      <td>495</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>166</td>\n",
       "      <td>274</td>\n",
       "      <td>62</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Easy  Medium  Hard  Extra Hard\n",
       "True    422     495    20         NaN\n",
       "False   166     274    62       104.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"hardness\"] == hardness][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(hardness)\n",
    "        for hardness in (\"Easy\", \"Medium\", \"Hard\", \"Extra Hard\")\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bar</th>\n",
       "      <th>Line</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Stacked Bar</th>\n",
       "      <th>Grouping Line</th>\n",
       "      <th>Pie</th>\n",
       "      <th>Grouping Scatter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>766</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>280</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "      <td>73</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bar  Line  Scatter  Stacked Bar  Grouping Line  Pie  Grouping Scatter\n",
       "True   766    32       46            6            NaN   68                19\n",
       "False  280    96       88           73           27.0   21                21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"chart\"] == chart][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(chart)\n",
    "        \n",
    "        for chart in preds_df[\"chart\"].unique()\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/vxnli-v0\n",
      "Configuration saved in ../data/vxnli-v0/config.json\n",
      "Model weights saved in ../data/vxnli-v0/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0/special_tokens_map.json\n",
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kwkty/vxnli-v0\n",
      "   956d0f7..7987400  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kwkty/vxnli-v0\n",
      "   7987400..358b03d  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if push_model_to_huggingface_hub:\n",
    "    # huggingface_hub.notebook_login()\n",
    "\n",
    "    trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63d5e78cacc7bbb3aa8f0f1cd8b8015c0d580cb8c6884f2092d527cf506d691b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
