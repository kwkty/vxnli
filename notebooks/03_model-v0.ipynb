{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Model v0\n",
    "\n",
    "Model v0 is an ML model for typical V-NLI, which accepts text and tabular data as input, and returns the corresponding figure.\n",
    "\n",
    "We adopt [TAPEX](https://arxiv.org/abs/2107.07653), a pre-trained [BART](https://arxiv.org/abs/1910.13461) model, as a base model.\n",
    "And we use almost the same hyperparameters as TAPEX.\n",
    "\n",
    "We fine-tune the model with the two nvBench datasets preprocessed in the previous notebook.\n",
    "One model is for the user study, and another is for real-world usage (Check the details in the previous notebook).\n",
    "\n",
    "We use Hugging Face Transformers, one of the most famous NLP libraries, for implementation.\n",
    "Primarily we refer to [this TAPEX example](https://github.com/huggingface/transformers/blob/main/examples/research_projects/tapex/run_wikisql_with_tapex.py\n",
    ").\n",
    "\n",
    "As a result, the exact match ratio of the user study model gets to be ~90% for the test dataset, and the model for real-world usage gets to be ~60%.\n",
    "It's not comparable to the existing work because we adopt a different way to preprocess the nvBench dataset.\n",
    "However, our goal is not to improve an ML model for V-NLI but to propose a novel UI for data visualization.\n",
    "\n",
    "In the final user study, we use this model as the baseline model to compare our proposed interface with typical V-NLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/\"\n",
    "load_model_from_last_checkpoint: bool = False\n",
    "push_model_to_huggingface_hub: bool = True\n",
    "skip_training: bool = False\n",
    "\n",
    "# If user_study is True, the model is trained by the preprocessed dataset with the stratified sampling\n",
    "# Otherwise, the group shuffled dataset is used\n",
    "# See the preprocess notebook for the details of the datasets\n",
    "user_study: bool = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BartConfig,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    EvalPrediction,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TapexTokenizer,\n",
    "    trainer_utils,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.set_seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATA_DIR: Path = Path(data_dir)\n",
    "DATABASE_DIR: Path = DATA_DIR.joinpath(\"database\")\n",
    "\n",
    "if user_study:\n",
    "    MODEL_NAME: str = \"vxnli-v0-user-study\"\n",
    "    PREPROCESSED_NVBENCH_DIR: Path = DATA_DIR.joinpath(\n",
    "        \"preprocessed-nvBench/stratified\"\n",
    "    )\n",
    "else:\n",
    "    MODEL_NAME: str = \"vxnli-v0\"\n",
    "    PREPROCESSED_NVBENCH_DIR: Path = DATA_DIR.joinpath(\"preprocessed-nvBench/grouped\")\n",
    "\n",
    "DATASET_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"{MODEL_NAME}.hf\")\n",
    "MODEL_OUTPUT_DIR: Path = DATA_DIR.joinpath(MODEL_NAME)\n",
    "PREDS_OUTPUT_PATH: Path = DATA_DIR.joinpath(f\"{MODEL_NAME}-preds.csv\")\n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "BASE_MODEL: str = \"microsoft/tapex-base-finetuned-wtq\"\n",
    "MAX_SOURCE_LENGTH: int = 1024\n",
    "MAX_TARGET_LENGTH: int = 124\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TapexTokenizer.from_pretrained(\n",
    "    BASE_MODEL, use_fast=True, add_prefix_space=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 11311,  4832,  5552,  1721,   346,     9,  4133,  3236,   112,\n",
       "          4832,  5378,   625,   181,  2582,  1721,  8176,  3236,   132,  4832,\n",
       "          2084,   261,  6782,  2269,  2927, 12834,  1721,  4268,  3236,   155,\n",
       "          4832,  5473, 26875, 42771,  6071,  1721,  5913,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "tokenizer(\n",
    "    table=pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n",
    "            \"Number of movies\": [\"87\", \"53\", \"69\"],\n",
    "        }\n",
    "    ),\n",
    "    answer=\"how many movies does Leonardo Di Caprio have?\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BartConfig.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    no_repeat_ngram_size=0,\n",
    "    max_length=MAX_SOURCE_LENGTH,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "if load_model_from_last_checkpoint:\n",
    "    model = trainer_utils.get_last_checkpoint(MODEL_OUTPUT_DIR)\n",
    "else:\n",
    "    model = BASE_MODEL\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    model,\n",
    "    config=model_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>5.475398e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>3.059093e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1.026885e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2.295667e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5.927022e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id product_type_code product_name  product_price\n",
       "0           1          Hardware        Apple   5.475398e+07\n",
       "1           2           Clothes        jcrew   3.059093e+07\n",
       "2           3          Hardware        Apple   1.026885e+04\n",
       "3           4          Hardware        Apple   2.295667e+07\n",
       "4           5           Clothes        jcrew   5.927022e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    db_path = DATABASE_DIR.joinpath(f\"{db_id}/{db_id}.sqlite\")\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        return pd.read_sql(f\"SELECT * FROM {table_name}\", con)\n",
    "\n",
    "\n",
    "# Example\n",
    "load_table(\"customers_and_products_contacts\", \"products\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>54753982.574522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>30590929.528306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>10268.85297069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>22956668.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5927021.8748021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_type_code product_name    product_price\n",
       "0          1          hardware        apple  54753982.574522\n",
       "1          2           clothes        jcrew  30590929.528306\n",
       "2          3          hardware        apple   10268.85297069\n",
       "3          4          hardware        apple  22956668.699482\n",
       "4          5           clothes        jcrew  5927021.8748021"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={col: col.lower() for col in df.columns})\n",
    "\n",
    "    for col_name, col_dtype in zip(df.columns, df.dtypes):\n",
    "        if pd.api.types.is_string_dtype(col_dtype):\n",
    "            df[col_name] = df[col_name].str.lower()\n",
    "\n",
    "    # The TAPEX tokenizer raises an error when the table contains non-str columns\n",
    "    df = df.astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocess_table(load_table(\"customers_and_products_contacts\", \"products\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functools.cache is supported in python3.9+, but use lru_cache to support python3.7+\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_and_preprocess_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    table = load_table(db_id, table_name)\n",
    "    table = preprocess_table(table)\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    table = load_and_preprocess_table(example[\"db_id\"], example[\"table\"])\n",
    "\n",
    "    query = example[\"question\"]\n",
    "    answer = example[\"vega_zero\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        table=table,\n",
    "        query=query,\n",
    "        answer=answer,\n",
    "        max_length=MAX_SOURCE_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        answer=answer,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12485\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1649\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'SQL', 'table', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1592\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET_OUTPUT_DIR.exists():\n",
    "    # load_from_dist doesn't support pathlib.Path\n",
    "    dataset = datasets.load_from_disk(str(DATASET_OUTPUT_DIR))\n",
    "else:\n",
    "    dataset = datasets.load_dataset(\n",
    "        \"csv\",\n",
    "        data_files={\n",
    "            # load_dataset doesn't support pathlib.Path\n",
    "            \"train\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"train.csv\")),\n",
    "            \"test\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"test.csv\")),\n",
    "            \"validation\": str(PREPROCESSED_NVBENCH_DIR.joinpath(\"val.csv\")),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        preprocess_dataset,\n",
    "        batched=False,\n",
    "        num_proc=multiprocessing.cpu_count(),\n",
    "    )\n",
    "\n",
    "    # save_to_disk doesn't support pathlib.Path\n",
    "    dataset.save_to_disk(str(DATASET_OUTPUT_DIR))\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return exact_match.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface trainer uses environment variables to configure mlflow\n",
    "# https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/integrations.py#L884\n",
    "\n",
    "# MLFlow experiment name must be updated if you update training arguments\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = f\"{MODEL_NAME}-{datetime.now().strftime('%Y%m%d%H%M')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kwkty/vxnli-v0-user-study into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=Seq2SeqTrainingArguments(\n",
    "        output_dir=MODEL_OUTPUT_DIR,\n",
    "        predict_with_generate=True,\n",
    "        num_train_epochs=50,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=True,\n",
    "        metric_for_best_model=\"exact_match\",\n",
    "        push_to_hub=push_model_to_huggingface_hub,\n",
    "        report_to=\"mlflow\",\n",
    "    ),\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=5),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 12485\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19550\n",
      "  Number of trainable parameters = 139420416\n",
      "2022/11/25 08:26:49 INFO mlflow.tracking.fluent: Experiment with name 'vxnli-v0-user-study-202211250826' does not exist. Creating a new experiment.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4301' max='19550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4301/19550 53:31 < 3:09:52, 1.34 it/s, Epoch 11/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.900126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.900126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.944724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.943467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.022604</td>\n",
       "      <td>0.935930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.953518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.953518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>0.944724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.939070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.951005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.949121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-391\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-391/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-391/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-391/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-391/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-782\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-782/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-782/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-1173\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-1173/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-1173/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-1173/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-1173/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-391] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-782] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-1564\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-1564/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-1564/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-1955\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-1955/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-1955/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-1955/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-1955/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-1564] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-2346\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-2346/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-2346/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-1173] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-1955] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-2737\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-2737/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-2737/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-2737/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-2737/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-3128\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-3128/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-3128/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-2737] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-3519\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-3519/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-3519/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-3519/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-3519/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-3128] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-3910\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-3910/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-3910/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-3519] due to args.save_total_limit\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1592\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../data/vxnli-v0-user-study/checkpoint-4301\n",
      "Configuration saved in ../data/vxnli-v0-user-study/checkpoint-4301/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/checkpoint-4301/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/checkpoint-4301/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/checkpoint-4301/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-3910] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/vxnli-v0-user-study/checkpoint-2346 (score: 0.9535175879396985).\n",
      "Deleting older checkpoint [../data/vxnli-v0-user-study/checkpoint-4301] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1649\n",
      "  Batch size = 32\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.014960955828428268,\n",
       " 'eval_exact_match': 0.9405700424499697,\n",
       " 'eval_runtime': 122.1686,\n",
       " 'eval_samples_per_second': 13.498,\n",
       " 'eval_steps_per_second': 0.426,\n",
       " 'epoch': 11.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate must be called for the model card\n",
    "\n",
    "trainer.evaluate(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ds: Dataset) -> List[str]:\n",
    "    preds = trainer.predict(\n",
    "        ds,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "    )\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return [pred.strip() for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, SQL, vega_zero, question, query, hardness. If table, chart, db_id, SQL, vega_zero, question, query, hardness are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1649\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['mark bar encoding x county_name y aggregate none population',\n",
       "  'mark bar encoding x nationality y aggregate count nationality transform group x sort y desc',\n",
       "  'mark bar encoding x crs_code y aggregate count crs_code transform group x sort x asc',\n",
       "  'mark bar encoding x name y aggregate none code transform filter price between 60 and 120 sort y asc',\n",
       "  'mark arc encoding x affiliation y aggregate sum enrollment transform group x'],\n",
       " ['mark bar encoding x county_name y aggregate none population',\n",
       "  'mark bar encoding x nationality y aggregate count nationality transform group x sort y desc',\n",
       "  'mark bar encoding x crs_code y aggregate count crs_code transform group x sort x asc',\n",
       "  'mark bar encoding x name y aggregate none code transform filter price between 60 and 120 sort y asc',\n",
       "  'mark arc encoding x affiliation y aggregate sum enrollment transform group x'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(dataset[\"test\"])\n",
    "\n",
    "preds[:5], dataset[\"test\"][\"vega_zero\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.9023650697392359}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match.compute(\n",
    "    predictions=preds,\n",
    "    references=dataset[\"test\"][\"vega_zero\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>SQL</th>\n",
       "      <th>table</th>\n",
       "      <th>pred</th>\n",
       "      <th>exact_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>election</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize BAR SELECT County_name , Population ...</td>\n",
       "      <td>what are the name and population of each count...</td>\n",
       "      <td>mark bar encoding x county_name y aggregate no...</td>\n",
       "      <td>SELECT County_name , Population FROM county</td>\n",
       "      <td>county</td>\n",
       "      <td>mark bar encoding x county_name y aggregate no...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>swimming</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Nationality , COUNT(Natio...</td>\n",
       "      <td>return a bar chart about the distribution of n...</td>\n",
       "      <td>mark bar encoding x nationality y aggregate co...</td>\n",
       "      <td>SELECT Nationality , COUNT(Nationality) FROM s...</td>\n",
       "      <td>swimmer</td>\n",
       "      <td>mark bar encoding x nationality y aggregate co...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>college_1</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT CRS_CODE , count(*) FROM ...</td>\n",
       "      <td>visualize a bar chart for how many sections do...</td>\n",
       "      <td>mark bar encoding x crs_code y aggregate count...</td>\n",
       "      <td>SELECT CRS_CODE , count(*) FROM CLASS GROUP BY...</td>\n",
       "      <td>class</td>\n",
       "      <td>mark bar encoding x crs_code y aggregate count...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manufactory_1</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Name , Code FROM products...</td>\n",
       "      <td>for those products with a price between 60 and...</td>\n",
       "      <td>mark bar encoding x name y aggregate none code...</td>\n",
       "      <td>SELECT Name , Code FROM products WHERE price B...</td>\n",
       "      <td>products</td>\n",
       "      <td>mark bar encoding x name y aggregate none code...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>Pie</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize PIE SELECT Affiliation , sum(enrollm...</td>\n",
       "      <td>display a pie chart for what are the total enr...</td>\n",
       "      <td>mark arc encoding x affiliation y aggregate su...</td>\n",
       "      <td>SELECT Affiliation , sum(enrollment) FROM univ...</td>\n",
       "      <td>university</td>\n",
       "      <td>mark arc encoding x affiliation y aggregate su...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>local_govt_in_alabama</td>\n",
       "      <td>Pie</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Visualize PIE SELECT Event_Details , COUNT(Eve...</td>\n",
       "      <td>group and count details for the events using a...</td>\n",
       "      <td>mark arc encoding x event_details y aggregate ...</td>\n",
       "      <td>SELECT Event_Details , COUNT(Event_Details) FR...</td>\n",
       "      <td>events</td>\n",
       "      <td>mark arc encoding x event_details y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>bike_1</td>\n",
       "      <td>Line</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Visualize LINE SELECT date , COUNT(date) FROM ...</td>\n",
       "      <td>please show the trend about the number of days...</td>\n",
       "      <td>mark line encoding x date y aggregate count da...</td>\n",
       "      <td>SELECT date , COUNT(date) FROM weather WHERE m...</td>\n",
       "      <td>weather</td>\n",
       "      <td>mark line encoding x date y aggregate count da...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>hr_1</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Extra Hard</td>\n",
       "      <td>Visualize BAR SELECT HIRE_DATE , COUNT(HIRE_DA...</td>\n",
       "      <td>for all employees who have the letters d or s ...</td>\n",
       "      <td>mark bar encoding x hire_date y aggregate coun...</td>\n",
       "      <td>SELECT HIRE_DATE , COUNT(HIRE_DATE) FROM emplo...</td>\n",
       "      <td>employees</td>\n",
       "      <td>mark bar encoding x hire_date y aggregate coun...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>bike_1</td>\n",
       "      <td>Line</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Visualize LINE SELECT date , COUNT(date) FROM ...</td>\n",
       "      <td>please show the trend about the number of days...</td>\n",
       "      <td>mark line encoding x date y aggregate count da...</td>\n",
       "      <td>SELECT date , COUNT(date) FROM weather WHERE m...</td>\n",
       "      <td>weather</td>\n",
       "      <td>mark line encoding x date y aggregate count da...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>news_report</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Visualize BAR SELECT Nationality , COUNT(*) FR...</td>\n",
       "      <td>show the different nationalities and the numbe...</td>\n",
       "      <td>mark bar encoding x nationality y aggregate co...</td>\n",
       "      <td>SELECT Nationality , COUNT(*) FROM journalist ...</td>\n",
       "      <td>journalist</td>\n",
       "      <td>mark bar encoding x nationality y aggregate co...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1649 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      db_id chart    hardness  \\\n",
       "0                  election   Bar        Easy   \n",
       "1                  swimming   Bar      Medium   \n",
       "2                 college_1   Bar      Medium   \n",
       "3             manufactory_1   Bar      Medium   \n",
       "4     university_basketball   Pie        Easy   \n",
       "...                     ...   ...         ...   \n",
       "1644  local_govt_in_alabama   Pie        Easy   \n",
       "1645                 bike_1  Line        Hard   \n",
       "1646                   hr_1   Bar  Extra Hard   \n",
       "1647                 bike_1  Line        Hard   \n",
       "1648            news_report   Bar      Medium   \n",
       "\n",
       "                                                  query  \\\n",
       "0     Visualize BAR SELECT County_name , Population ...   \n",
       "1     Visualize BAR SELECT Nationality , COUNT(Natio...   \n",
       "2     Visualize BAR SELECT CRS_CODE , count(*) FROM ...   \n",
       "3     Visualize BAR SELECT Name , Code FROM products...   \n",
       "4     Visualize PIE SELECT Affiliation , sum(enrollm...   \n",
       "...                                                 ...   \n",
       "1644  Visualize PIE SELECT Event_Details , COUNT(Eve...   \n",
       "1645  Visualize LINE SELECT date , COUNT(date) FROM ...   \n",
       "1646  Visualize BAR SELECT HIRE_DATE , COUNT(HIRE_DA...   \n",
       "1647  Visualize LINE SELECT date , COUNT(date) FROM ...   \n",
       "1648  Visualize BAR SELECT Nationality , COUNT(*) FR...   \n",
       "\n",
       "                                               question  \\\n",
       "0     what are the name and population of each count...   \n",
       "1     return a bar chart about the distribution of n...   \n",
       "2     visualize a bar chart for how many sections do...   \n",
       "3     for those products with a price between 60 and...   \n",
       "4     display a pie chart for what are the total enr...   \n",
       "...                                                 ...   \n",
       "1644  group and count details for the events using a...   \n",
       "1645  please show the trend about the number of days...   \n",
       "1646  for all employees who have the letters d or s ...   \n",
       "1647  please show the trend about the number of days...   \n",
       "1648  show the different nationalities and the numbe...   \n",
       "\n",
       "                                              vega_zero  \\\n",
       "0     mark bar encoding x county_name y aggregate no...   \n",
       "1     mark bar encoding x nationality y aggregate co...   \n",
       "2     mark bar encoding x crs_code y aggregate count...   \n",
       "3     mark bar encoding x name y aggregate none code...   \n",
       "4     mark arc encoding x affiliation y aggregate su...   \n",
       "...                                                 ...   \n",
       "1644  mark arc encoding x event_details y aggregate ...   \n",
       "1645  mark line encoding x date y aggregate count da...   \n",
       "1646  mark bar encoding x hire_date y aggregate coun...   \n",
       "1647  mark line encoding x date y aggregate count da...   \n",
       "1648  mark bar encoding x nationality y aggregate co...   \n",
       "\n",
       "                                                    SQL       table  \\\n",
       "0           SELECT County_name , Population FROM county      county   \n",
       "1     SELECT Nationality , COUNT(Nationality) FROM s...     swimmer   \n",
       "2     SELECT CRS_CODE , count(*) FROM CLASS GROUP BY...       class   \n",
       "3     SELECT Name , Code FROM products WHERE price B...    products   \n",
       "4     SELECT Affiliation , sum(enrollment) FROM univ...  university   \n",
       "...                                                 ...         ...   \n",
       "1644  SELECT Event_Details , COUNT(Event_Details) FR...      events   \n",
       "1645  SELECT date , COUNT(date) FROM weather WHERE m...     weather   \n",
       "1646  SELECT HIRE_DATE , COUNT(HIRE_DATE) FROM emplo...   employees   \n",
       "1647  SELECT date , COUNT(date) FROM weather WHERE m...     weather   \n",
       "1648  SELECT Nationality , COUNT(*) FROM journalist ...  journalist   \n",
       "\n",
       "                                                   pred  exact_matched  \n",
       "0     mark bar encoding x county_name y aggregate no...           True  \n",
       "1     mark bar encoding x nationality y aggregate co...           True  \n",
       "2     mark bar encoding x crs_code y aggregate count...           True  \n",
       "3     mark bar encoding x name y aggregate none code...           True  \n",
       "4     mark arc encoding x affiliation y aggregate su...           True  \n",
       "...                                                 ...            ...  \n",
       "1644  mark arc encoding x event_details y aggregate ...           True  \n",
       "1645  mark line encoding x date y aggregate count da...           True  \n",
       "1646  mark bar encoding x hire_date y aggregate coun...           True  \n",
       "1647  mark line encoding x date y aggregate count da...           True  \n",
       "1648  mark bar encoding x nationality y aggregate co...           True  \n",
       "\n",
       "[1649 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = dataset[\"test\"].to_pandas()\n",
    "preds_df = preds_df.drop(columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "preds_df[\"pred\"] = preds\n",
    "preds_df[\"exact_matched\"] = preds_df[\"pred\"] == preds_df[\"vega_zero\"]\n",
    "\n",
    "preds_df.to_csv(PREDS_OUTPUT_PATH)\n",
    "\n",
    "preds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easy</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Hard</th>\n",
       "      <th>Extra Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>527</td>\n",
       "      <td>677</td>\n",
       "      <td>183</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Easy  Medium  Hard  Extra Hard\n",
       "True    527     677   183         101\n",
       "False    42      58    22          39"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"hardness\"] == hardness][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(hardness)\n",
    "        for hardness in (\"Easy\", \"Medium\", \"Hard\", \"Extra Hard\")\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bar</th>\n",
       "      <th>Pie</th>\n",
       "      <th>Line</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Grouping Line</th>\n",
       "      <th>Stacked Bar</th>\n",
       "      <th>Grouping Scatter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1143</td>\n",
       "      <td>133</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bar  Pie  Line  Scatter  Grouping Line  Stacked Bar  Grouping Scatter\n",
       "True   1143  133    73       29             31           50                29\n",
       "False    91   22    24       13              5            2                 4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"chart\"] == chart][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(chart)\n",
    "        \n",
    "        for chart in preds_df[\"chart\"].unique()\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/vxnli-v0-user-study\n",
      "Configuration saved in ../data/vxnli-v0-user-study/config.json\n",
      "Model weights saved in ../data/vxnli-v0-user-study/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/vxnli-v0-user-study/tokenizer_config.json\n",
      "Special tokens file saved in ../data/vxnli-v0-user-study/special_tokens_map.json\n",
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kwkty/vxnli-v0-user-study\n",
      "   1fdfca4..9dda6e8  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kwkty/vxnli-v0-user-study\n",
      "   9dda6e8..c24914b  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if push_model_to_huggingface_hub:\n",
    "    # huggingface_hub.notebook_login()\n",
    "\n",
    "    trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63d5e78cacc7bbb3aa8f0f1cd8b8015c0d580cb8c6884f2092d527cf506d691b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
