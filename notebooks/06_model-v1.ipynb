{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Model v1\n",
    "\n",
    "Model v1 is a ML model for the proposed UI which accepts \"any\" inputs.\n",
    "\n",
    "We fine-tune model-v0 with the custom dataset annotated in the previous notebook.\n",
    "We modify the tokenizer from the original one to support variable length and keyword arguments.\n",
    "\n",
    "As a result, the exact match ratio gets to be ~62% for the test dataset.\n",
    "This model is uploaded to [Huggingface Hub](https://huggingface.co/kwkty/vxnli-v0).\n",
    "Besides, we fine-tine TAPEX, not model-v0, with the custom dataset.\n",
    "However, the performance is a bit lower (~60%) than the former one.\n",
    "\n",
    "We use model-v1 in the final user study to compare our proposed interface with typical V-NLI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/\"\n",
    "push_model_to_huggingface_hub: bool = True\n",
    "use_wandb: bool = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    BartConfig,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    EvalPrediction,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TapexTokenizer,\n",
    "    trainer_utils,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.set_seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATA_DIR: Path = Path(data_dir)\n",
    "\n",
    "MODEL_NAME: str = \"vxnli-v1\"\n",
    "\n",
    "DATABASE_DIR: Path = DATA_DIR.joinpath(\"datasets/nvBench/database\")\n",
    "DATASET_DIR: Path = DATA_DIR.joinpath(f\"datasets/{MODEL_NAME}/\")\n",
    "DATASET_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"datasets/{MODEL_NAME}.hf/\")\n",
    "\n",
    "MODEL_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"models/{MODEL_NAME}/\")\n",
    "RESULT_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"results/{MODEL_NAME}/\")\n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "# BASE_MODEL: str = \"microsoft/tapex-base-finetuned-wtq\"\n",
    "BASE_MODEL: str = \"kwkty/vxnli-v0\"\n",
    "\n",
    "MAX_SOURCE_LENGTH: int = 1024\n",
    "MAX_TARGET_LENGTH: int = 124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TapexTokenizer.from_pretrained(\n",
    "    BASE_MODEL, use_fast=True, add_prefix_space=True\n",
    ")\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [\"[arg]\", \"[kwarg]\", \"[eq]\"]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50268, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = BartConfig.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    no_repeat_ngram_size=0,\n",
    "    max_length=MAX_SOURCE_LENGTH,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    config=model_config,\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>5.475398e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>3.059093e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1.026885e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2.295667e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5.927022e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id product_type_code product_name  product_price\n",
       "0           1          Hardware        Apple   5.475398e+07\n",
       "1           2           Clothes        jcrew   3.059093e+07\n",
       "2           3          Hardware        Apple   1.026885e+04\n",
       "3           4          Hardware        Apple   2.295667e+07\n",
       "4           5           Clothes        jcrew   5.927022e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    db_path = DATABASE_DIR.joinpath(f\"{db_id}/{db_id}.sqlite\")\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        return pd.read_sql(f\"SELECT * FROM {table_name}\", con)\n",
    "\n",
    "\n",
    "# Example\n",
    "load_table(\"customers_and_products_contacts\", \"products\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>54753982.574522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>30590929.528306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>10268.85297069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>hardware</td>\n",
       "      <td>apple</td>\n",
       "      <td>22956668.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>clothes</td>\n",
       "      <td>jcrew</td>\n",
       "      <td>5927021.8748021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_type_code product_name    product_price\n",
       "0          1          hardware        apple  54753982.574522\n",
       "1          2           clothes        jcrew  30590929.528306\n",
       "2          3          hardware        apple   10268.85297069\n",
       "3          4          hardware        apple  22956668.699482\n",
       "4          5           clothes        jcrew  5927021.8748021"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={col: col.lower() for col in df.columns})\n",
    "\n",
    "    # The TAPEX tokenizer raises an error when the table contains non-str columns\n",
    "    df = df.astype(str)\n",
    "\n",
    "    for col_name, col_dtype in zip(df.columns, df.dtypes):\n",
    "        df[col_name] = df[col_name].str.lower()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocess_table(load_table(\"customers_and_products_contacts\", \"products\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functools.cache is supported in python3.9+, but use lru_cache to support python3.7+\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_and_preprocess_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    table = load_table(db_id, table_name)\n",
    "    table = preprocess_table(table)\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    table = load_and_preprocess_table(example[\"db_id\"], example[\"table\"])\n",
    "\n",
    "    query = example[\"query\"]\n",
    "    answer = example[\"vega_zero\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        table=table,\n",
    "        query=query,\n",
    "        answer=answer,\n",
    "        max_length=MAX_SOURCE_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        answer=answer,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(*args, **kwargs) -> str:\n",
    "    args = (str(arg) for arg in args)\n",
    "    args = \" [arg] \".join(args)\n",
    "    args = f\"[arg] {args}\"\n",
    "\n",
    "    kwargs = (f\"{k} [eq] {v}\" for k, v in kwargs.items())\n",
    "    kwargs = \" [kwarg] \".join(kwargs)\n",
    "    kwargs = f\"[kwarg] {kwargs}\"\n",
    "\n",
    "    return f\"{args} {kwargs}\".lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vxnli_dataset(subset: str) -> Dataset:\n",
    "    # datasets.load_dataset(\"json\", PATH) raises an json parse error\n",
    "    # this is probably because it cannot parse the args and kwargs columns (list and dict types) well\n",
    "\n",
    "    df = pd.read_json(DATASET_DIR.joinpath(f\"{subset}.ndjson\"), lines=True)\n",
    "    df[\"query\"] = df.apply(\n",
    "        lambda row: preprocess_query(*row[\"args\"], **row[\"kwargs\"]), axis=1\n",
    "    )\n",
    "    df = df.drop(columns=[\"args\", \"kwargs\"])\n",
    "\n",
    "    return Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1050\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 225\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET_OUTPUT_DIR.exists():\n",
    "    # load_from_dist doesn't support pathlib.Path\n",
    "    dataset = datasets.load_from_disk(str(DATASET_OUTPUT_DIR))\n",
    "else:\n",
    "    dataset = DatasetDict()\n",
    "\n",
    "    dataset[\"train\"] = load_vxnli_dataset(\"train\")\n",
    "    dataset[\"test\"] = load_vxnli_dataset(\"test\")\n",
    "    dataset[\"validation\"] = load_vxnli_dataset(\"val\")\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        preprocess_dataset,\n",
    "        batched=False,\n",
    "        num_proc=multiprocessing.cpu_count(),\n",
    "    )\n",
    "\n",
    "    # save_to_disk doesn't support pathlib.Path\n",
    "    dataset.save_to_disk(str(DATASET_OUTPUT_DIR))\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return exact_match.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vxnli/notebooks/../data/models/vxnli-v1 is already a clone of https://huggingface.co/kwkty/vxnli-v1. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=Seq2SeqTrainingArguments(\n",
    "        output_dir=MODEL_OUTPUT_DIR,\n",
    "        predict_with_generate=True,\n",
    "        num_train_epochs=50,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=True,\n",
    "        metric_for_best_model=\"exact_match\",\n",
    "        push_to_hub=push_model_to_huggingface_hub,\n",
    "        report_to=\"wandb\" if use_wandb else \"none\",\n",
    "    ),\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=5),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1050\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6600\n",
      "  Number of trainable parameters = 139422720\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkwkty\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/vxnli/data/wandb/run-20221217_014326-2hb4u4gr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kwkty/vxnli/runs/2hb4u4gr\" target=\"_blank\">../data/models/vxnli-v1</a></strong> to <a href=\"https://wandb.ai/kwkty/vxnli\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='6600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/6600 15:10 < 1:00:46, 1.45 it/s, Epoch 10/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.193996</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.170474</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.252346</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.232647</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.211964</td>\n",
       "      <td>0.617778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.225278</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.261872</td>\n",
       "      <td>0.564444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.259646</td>\n",
       "      <td>0.537778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.225496</td>\n",
       "      <td>0.564444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-132\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-132/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-132/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-132/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-132/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-132/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-1188] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-264\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-264/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-264/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-264/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-264/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-264/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-132] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-396\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-396/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-396/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-396/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-396/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-396/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-528\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-528/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-528/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-528/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-528/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-528/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-396] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-660\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-660/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-660/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-660/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-660/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-660/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-264] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-528] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-792\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-792/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-792/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-792/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-792/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-792/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-924\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-924/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-924/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-924/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-924/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-924/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-792] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-1056\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-1056/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-1056/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-1056/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-1056/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-1056/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-924] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-1188\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-1188/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-1188/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-1188/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-1188/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-1188/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-1056] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v1/checkpoint-1320\n",
      "Configuration saved in ../data/models/vxnli-v1/checkpoint-1320/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/checkpoint-1320/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/checkpoint-1320/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/checkpoint-1320/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/checkpoint-1320/added_tokens.json\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-1188] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/models/vxnli-v1/checkpoint-660 (score: 0.6177777777777778).\n",
      "Deleting older checkpoint [../data/models/vxnli-v1/checkpoint-1320] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1320, training_loss=0.02755795708208373, metrics={'train_runtime': 914.2834, 'train_samples_per_second': 57.422, 'train_steps_per_second': 7.219, 'total_flos': 6170953342095360.0, 'train_loss': 0.02755795708208373, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2780759036540985,\n",
       " 'eval_exact_match': 0.6222222222222222,\n",
       " 'eval_runtime': 20.6895,\n",
       " 'eval_samples_per_second': 10.875,\n",
       " 'eval_steps_per_second': 1.402,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate must be called for the model card\n",
    "\n",
    "trainer.evaluate(dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ds: Dataset) -> List[str]:\n",
    "    preds = trainer.predict(\n",
    "        ds,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "    )\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return [pred.strip() for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: table, chart, db_id, hardness, query, vega_zero. If table, chart, db_id, hardness, query, vega_zero are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['mark bar encoding x name y aggregate none weight transform sort y asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x'],\n",
       " ['mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(dataset[\"test\"])\n",
    "\n",
    "preds[:5], dataset[\"test\"][\"vega_zero\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.6222222222222222}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match.compute(\n",
    "    predictions=preds,\n",
    "    references=dataset[\"test\"][\"vega_zero\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>table</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>query</th>\n",
       "      <th>pred</th>\n",
       "      <th>exact_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg]  [kwarg] use_bar_chart [eq] true [kwarg]...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg] use a bar chart [kwarg] x [eq] name [kwa...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg]  [kwarg] graph [eq] bar [kwarg] x [eq] n...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>[arg] scatter chart [arg] investor id and mean...</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>[arg]  [kwarg] graph_type [eq] scatter [kwarg]...</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>train_station</td>\n",
       "      <td>station</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x location y aggregate sum n...</td>\n",
       "      <td>[arg]  [kwarg] chart [eq] bar [kwarg] x [eq] p...</td>\n",
       "      <td>mark bar encoding x main_home y aggregate sum ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>train_station</td>\n",
       "      <td>station</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x location y aggregate sum n...</td>\n",
       "      <td>[arg] return sum(number_of_platforms) per loca...</td>\n",
       "      <td>mark bar encoding x location y aggregate sum n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>accounts</td>\n",
       "      <td>line</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>[arg] line chart [arg] the number of accounts ...</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>accounts</td>\n",
       "      <td>line</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>[arg]  [kwarg] x [eq] date_account_opened (tim...</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>accounts</td>\n",
       "      <td>line</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>[arg] draw a line chart [kwarg] x [eq] date_ac...</td>\n",
       "      <td>mark line encoding x date_account_opened y agg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           db_id         table  chart hardness  \\\n",
       "0                 candidate_poll        people    bar     Easy   \n",
       "1                 candidate_poll        people    bar     Easy   \n",
       "2                 candidate_poll        people    bar     Easy   \n",
       "3    tracking_share_transactions  transactions  point     Easy   \n",
       "4    tracking_share_transactions  transactions  point     Easy   \n",
       "..                           ...           ...    ...      ...   \n",
       "220                train_station       station    bar   Medium   \n",
       "221                train_station       station    bar   Medium   \n",
       "222       customers_and_invoices      accounts   line   Medium   \n",
       "223       customers_and_invoices      accounts   line   Medium   \n",
       "224       customers_and_invoices      accounts   line   Medium   \n",
       "\n",
       "                                             vega_zero  \\\n",
       "0    mark bar encoding x name y aggregate none weig...   \n",
       "1    mark bar encoding x name y aggregate none weig...   \n",
       "2    mark bar encoding x name y aggregate none weig...   \n",
       "3    mark point encoding x investor_id y aggregate ...   \n",
       "4    mark point encoding x investor_id y aggregate ...   \n",
       "..                                                 ...   \n",
       "220  mark bar encoding x location y aggregate sum n...   \n",
       "221  mark bar encoding x location y aggregate sum n...   \n",
       "222  mark line encoding x date_account_opened y agg...   \n",
       "223  mark line encoding x date_account_opened y agg...   \n",
       "224  mark line encoding x date_account_opened y agg...   \n",
       "\n",
       "                                                 query  \\\n",
       "0    [arg]  [kwarg] use_bar_chart [eq] true [kwarg]...   \n",
       "1    [arg] use a bar chart [kwarg] x [eq] name [kwa...   \n",
       "2    [arg]  [kwarg] graph [eq] bar [kwarg] x [eq] n...   \n",
       "3    [arg] scatter chart [arg] investor id and mean...   \n",
       "4    [arg]  [kwarg] graph_type [eq] scatter [kwarg]...   \n",
       "..                                                 ...   \n",
       "220  [arg]  [kwarg] chart [eq] bar [kwarg] x [eq] p...   \n",
       "221  [arg] return sum(number_of_platforms) per loca...   \n",
       "222  [arg] line chart [arg] the number of accounts ...   \n",
       "223  [arg]  [kwarg] x [eq] date_account_opened (tim...   \n",
       "224  [arg] draw a line chart [kwarg] x [eq] date_ac...   \n",
       "\n",
       "                                                  pred  exact_matched  \n",
       "0    mark bar encoding x name y aggregate none weig...          False  \n",
       "1    mark bar encoding x name y aggregate none weig...           True  \n",
       "2    mark bar encoding x name y aggregate none weig...           True  \n",
       "3    mark point encoding x investor_id y aggregate ...           True  \n",
       "4    mark point encoding x investor_id y aggregate ...           True  \n",
       "..                                                 ...            ...  \n",
       "220  mark bar encoding x main_home y aggregate sum ...          False  \n",
       "221  mark bar encoding x location y aggregate sum n...           True  \n",
       "222  mark line encoding x date_account_opened y agg...           True  \n",
       "223  mark line encoding x date_account_opened y agg...           True  \n",
       "224  mark line encoding x date_account_opened y agg...           True  \n",
       "\n",
       "[225 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = dataset[\"test\"].to_pandas()\n",
    "preds_df = preds_df.drop(columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "preds_df[\"pred\"] = preds\n",
    "preds_df[\"exact_matched\"] = preds_df[\"pred\"] == preds_df[\"vega_zero\"]\n",
    "\n",
    "preds_df.to_csv(RESULT_OUTPUT_DIR.joinpath(\"prediction.csv\"))\n",
    "\n",
    "preds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easy</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Hard</th>\n",
       "      <th>Extra Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Easy  Medium  Hard  Extra Hard\n",
       "True     57      74     7           2\n",
       "False    21      34    14          16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"hardness\"] == hardness][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(hardness)\n",
    "        for hardness in (\"Easy\", \"Medium\", \"Hard\", \"Extra Hard\")\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "      <th>point</th>\n",
       "      <th>arc</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>96</td>\n",
       "      <td>17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bar  point   arc  line\n",
       "True    96     17  15.0    12\n",
       "False   63     13   NaN     9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_df[preds_df[\"chart\"] == chart][\"exact_matched\"]\n",
    "        .value_counts()\n",
    "        .rename(chart)\n",
    "        for chart in preds_df[\"chart\"].unique()\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/models/vxnli-v1\n",
      "Configuration saved in ../data/models/vxnli-v1/config.json\n",
      "Model weights saved in ../data/models/vxnli-v1/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v1/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v1/added_tokens.json\n",
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/kwkty/vxnli-v1\n",
      "   0e00d00..8e20aa5  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/kwkty/vxnli-v1\n",
      "   8e20aa5..da6f21a  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if push_model_to_huggingface_hub:\n",
    "    trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63d5e78cacc7bbb3aa8f0f1cd8b8015c0d580cb8c6884f2092d527cf506d691b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
