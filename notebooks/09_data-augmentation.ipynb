{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Data Augmentation\n",
    "\n",
    "TODO: Cleanup Documents & Codes\n",
    "TODO: Share Results with wandb (I was too cornered due to the internal deadline)\n",
    "\n",
    "Results\n",
    "\n",
    "| Params | Exact Match [%] |\n",
    "| :---: | :---: |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=model-v0 Augmentation=x1 | 0.717 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=True BASE_MODEL=tapex Augmentation=x1 | 0.533 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=True BASE_MODEL=tapex Augmentation=x0 | 0.470 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=tapex Augmentation=x1  | 0.7074074074074074 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=tapex Augmentation=x0.5 | 0.6444444444444445 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=tapex Augmentation=x1.5 | 0.6296296296296297 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=model-v0 Augmentation=x0.5 | 0.6148148148148148 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=False BASE_MODEL=model-v0 Augmentation=x1.5 | 0.6666666666666666 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=True BASE_MODEL=tapex Augmentation=x0.5 | 0.5740740740740741 |\n",
    "| REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF=True BASE_MODEL=tapex Augmentation=x1.5 | 0.5518518518518518 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/\"\n",
    "push_model_to_huggingface_hub: bool = True\n",
    "report_to_wandb: bool = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from random import Random\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import wandb\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    BartConfig,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    EvalPrediction,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    TapexTokenizer,\n",
    "    trainer_utils,\n",
    ")\n",
    "\n",
    "from vxnli._vega_zero import VegaZero, VegaZeroTransform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED: int = 123\n",
    "\n",
    "# Paths\n",
    "\n",
    "DATA_DIR: Path = Path(data_dir)\n",
    "\n",
    "MODEL_NAME: str = \"vxnli-v2beta1\"\n",
    "\n",
    "DATABASE_DIR: Path = DATA_DIR.joinpath(\"datasets/nvBench/database\")\n",
    "DATASET_DIR: Path = DATA_DIR.joinpath(f\"datasets/vxnli-v1/\")\n",
    "DATASET_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"datasets/{MODEL_NAME}.hf/\")\n",
    "\n",
    "MODEL_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"models/{MODEL_NAME}/\")\n",
    "RESULT_OUTPUT_DIR: Path = DATA_DIR.joinpath(f\"results/{MODEL_NAME}/\")\n",
    "\n",
    "# Model Parameters\n",
    "# BASE_MODEL: str = \"microsoft/tapex-base-finetuned-wtq\"\n",
    "BASE_MODEL: str = \"kwkty/vxnli-v0\"\n",
    "\n",
    "MAX_SOURCE_LENGTH: int = 1024\n",
    "MAX_TARGET_LENGTH: int = 124\n",
    "\n",
    "# Data Augmentation Parameters\n",
    "\n",
    "REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF: bool = False\n",
    "\n",
    "INSERT_FILTER_FRAC: float = 1.0  # 1.0\n",
    "\n",
    "INSERT_FILTER_KWARG_FRAC: float = 0.75\n",
    "SHUFFLE_FRAC: float = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "transformers.set_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(DATASET_DIR.joinpath(\"train.ndjson\"), lines=True)\n",
    "test_df = pd.read_json(DATASET_DIR.joinpath(\"test.ndjson\"), lines=True)\n",
    "val_df = pd.read_json(DATASET_DIR.joinpath(\"val.ndjson\"), lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_FILTER_EXAMPLES_FROM_TRAIN_DF:\n",
    "    train_df = train_df[~train_df[\"vega_zero\"].str.contains(\" filter \")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf89e6144f094c519c826d1a49c76870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d0ff2807754019a2671ac274954033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2e74a7ba104e7eb8581af74b038314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c167e2953f6749339b1136ab41233083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TapexTokenizer.from_pretrained(\n",
    "    BASE_MODEL, use_fast=True, add_prefix_space=True\n",
    ")\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [\"[arg]\", \"[kwarg]\", \"[eq]\"]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56f3fba9af84fc38f6e7dcc24f5b1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4509819e66646d99d0b800903a6f8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50268, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = BartConfig.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    no_repeat_ngram_size=0,\n",
    "    max_length=MAX_SOURCE_LENGTH,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    config=model_config,\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    db_path = DATABASE_DIR.joinpath(f\"{db_id}/{db_id}.sqlite\")\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        return pd.read_sql(f\"SELECT * FROM {table_name}\", con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_candidates(db_id: str, table: str) -> List[Tuple[str, int, int]]:\n",
    "    df = load_table(db_id, table)\n",
    "\n",
    "    columns = [\n",
    "        (col.lower(), dtype, df[col].unique().tolist())\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "        if pd.api.types.is_string_dtype(dtype) or pd.api.types.is_integer_dtype(dtype)\n",
    "    ]\n",
    "\n",
    "    return columns\n",
    "\n",
    "\n",
    "COLUMN_CANDIDATES = {\n",
    "    (db_id, table): get_column_candidates(db_id, table)\n",
    "    for _, db_id, table in train_df[[\"db_id\", \"table\"]].drop_duplicates().itertuples()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: vega_zero, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"vega_zero\"][test_df[\"vega_zero\"].str.contains(\" topk \")]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose Filter Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_KEYWORDS = [\n",
    "    \"filter\",\n",
    "    \"condition\",\n",
    "    \"cond\",\n",
    "    \"where\",\n",
    "    \"if_\",\n",
    "    \"when\",\n",
    "]\n",
    "\n",
    "INT_FILTER_PATTERNS = {\n",
    "    \"{col} < {val1}\": [\n",
    "        \"{col} < {val1}\",\n",
    "        \"{col} is lower than {val1}\",\n",
    "        \"{col} is smaller than {val1}\",\n",
    "    ],\n",
    "    \"{col} <= {val1}\": [\n",
    "        \"{col} <= {val1}\",\n",
    "        \"{col} is lower than or equal to {val1}\",\n",
    "        \"{col} is smaller than or equal to {val1}\",\n",
    "    ],\n",
    "    \"{col} > {val1}\": [\n",
    "        \"{col} > {val1}\",\n",
    "        \"{col} is bigger than {val1}\",\n",
    "        \"{col} is greater than {val1}\",\n",
    "    ],\n",
    "    \"{col} >= {val1}\": [\n",
    "        \"{col} >= {val1}\",\n",
    "        \"{col} is bigger than or equal to {val1}\",\n",
    "        \"{col} is greater than or equal to {val1}\",\n",
    "    ],\n",
    "    \"{col} = {val1}\": [\n",
    "        \"{col} = {val1}\",\n",
    "        \"{col} == {val1}\",\n",
    "        \"{col} is {val1}\",\n",
    "    ],\n",
    "    \"{col} != {val1}\": [\n",
    "        \"{col} != {val1}\",\n",
    "        \"{col} is not {val1}\",\n",
    "        \"{col} does not equal to {val1}\",\n",
    "    ],\n",
    "    \"{col} between {val1} and {val2}\": [\n",
    "        \"{col} between {val1} and {val2}\",\n",
    "        \"{col} in range({val1}, {val2})\",\n",
    "        \"{col} <- [{val1}, {val2}]\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "STR_FILTER_PATTERNS = {\n",
    "    '{col} = \"{val1}\"': [\n",
    "        '{col} = \"{val1}\"',\n",
    "        '{col} == \"{val1}\"',\n",
    "        '{col} is \"{val1}\"',\n",
    "    ],\n",
    "    '{col} != \"{val1}\"': [\n",
    "        '{col} != \"{val1}\"',\n",
    "        '{col} is not \"{val1}\"',\n",
    "        '{col} does not equal to \"{val1}\"',\n",
    "    ],\n",
    "}\n",
    "\n",
    "DOUBLE_FILTER_PATTERNS = {\n",
    "    \"{cond1} and {cond2}\": [\n",
    "        \"{cond1} and {cond2}\",\n",
    "        \"{cond1} && {cond2}\",\n",
    "        \"{cond1} & {cond2}\",\n",
    "    ],\n",
    "    \"{cond1} or {cond2}\": [\n",
    "        \"{cond1} or {cond2}\",\n",
    "        \"{cond1} || {cond2}\",\n",
    "        \"{cond1} | {cond2}\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "TRIPLE_FILTER_PATTERNS = {\n",
    "    \"{cond1} and {cond2} and {cond3}\": [\n",
    "        \"{cond1} and {cond2} and {cond3}\",\n",
    "        \"{cond1} && {cond2} && {cond3}\",\n",
    "        \"{cond1} & {cond2} & {cond3}\",\n",
    "    ],\n",
    "    \"{cond1} and {cond2} or {cond3}\": [\n",
    "        \"{cond1} and {cond2} or {cond3}\",\n",
    "        \"{cond1} && {cond2} || {cond3}\",\n",
    "        \"{cond1} & {cond2} | {cond3}\",\n",
    "    ],\n",
    "    \"{cond1} or {cond2} and {cond3}\": [\n",
    "        \"{cond1} or {cond2} and {cond3}\",\n",
    "        \"{cond1} || {cond2} && {cond3}\",\n",
    "        \"{cond1} | {cond2} & {cond3}\",\n",
    "    ],\n",
    "    \"{cond1} or+ {cond2} or {cond3}\": [\n",
    "        \"{cond1} or {cond2} or {cond3}\",\n",
    "        \"{cond1} || {cond2} || {cond3}\",\n",
    "        \"{cond1} | {cond2} | {cond3}\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>table</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>args</th>\n",
       "      <th>kwargs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swimmer</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none id</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'x': 'name', 'filter': 'nationality = \"Canada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>sports_competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x competition_type y aggrega...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'y': 'count', 'where': 'competition_type = \"F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>manufactory_1</td>\n",
       "      <td>products</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x name y aggregate count nam...</td>\n",
       "      <td>[count names, price &gt; 66, sort name in alphabet]</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>e_learning</td>\n",
       "      <td>student_course_enrolment</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x date_of_completion y aggre...</td>\n",
       "      <td>[count of records]</td>\n",
       "      <td>{'cond': 'course_id &gt;= 1 or+ course_id = 9 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>arc</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark arc encoding x all_neutral y aggregate no...</td>\n",
       "      <td>[arc]</td>\n",
       "      <td>{'filter': 'all_games != \"28–6\" or all_games =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>university</td>\n",
       "      <td>arc</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark arc encoding x affiliation y aggregate su...</td>\n",
       "      <td>[show a pie chart]</td>\n",
       "      <td>{'when': 'school_id &gt; 1', 'color': 'affiliatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x team_id y aggregate none...</td>\n",
       "      <td>[acc_home = \"7–1\" or team_name = \"Virginia Tech\"]</td>\n",
       "      <td>{'chart': 'scatter', 'x': 'team id', 'y': 'all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>college_2</td>\n",
       "      <td>section</td>\n",
       "      <td>line</td>\n",
       "      <td>Hard</td>\n",
       "      <td>mark line encoding x year y aggregate count ye...</td>\n",
       "      <td>[time series]</td>\n",
       "      <td>{'time': 'year', 'value': 'count', 'filter': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x all_home y aggregate mean ...</td>\n",
       "      <td>[draw hist]</td>\n",
       "      <td>{'x_axis': 'all home', 'y_axis': 'mean team_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>party_host</td>\n",
       "      <td>party</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x location y aggregate count...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'condition': 'first_year != \"2000\"', 'y_axis'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     db_id                     table  chart hardness  \\\n",
       "708               swimming                   swimmer    bar     Easy   \n",
       "434     sports_competition               competition    bar   Medium   \n",
       "460          manufactory_1                  products    bar   Medium   \n",
       "382             e_learning  student_course_enrolment    bar   Medium   \n",
       "101  university_basketball          basketball_match    arc     Easy   \n",
       "..                     ...                       ...    ...      ...   \n",
       "800  university_basketball                university    arc     Easy   \n",
       "71   university_basketball          basketball_match  point     Easy   \n",
       "484              college_2                   section   line     Hard   \n",
       "457  university_basketball          basketball_match    bar   Medium   \n",
       "644             party_host                     party    bar   Medium   \n",
       "\n",
       "                                             vega_zero  \\\n",
       "708       mark bar encoding x name y aggregate none id   \n",
       "434  mark bar encoding x competition_type y aggrega...   \n",
       "460  mark bar encoding x name y aggregate count nam...   \n",
       "382  mark bar encoding x date_of_completion y aggre...   \n",
       "101  mark arc encoding x all_neutral y aggregate no...   \n",
       "..                                                 ...   \n",
       "800  mark arc encoding x affiliation y aggregate su...   \n",
       "71   mark point encoding x team_id y aggregate none...   \n",
       "484  mark line encoding x year y aggregate count ye...   \n",
       "457  mark bar encoding x all_home y aggregate mean ...   \n",
       "644  mark bar encoding x location y aggregate count...   \n",
       "\n",
       "                                                  args  \\\n",
       "708                                                 []   \n",
       "434                                                 []   \n",
       "460   [count names, price > 66, sort name in alphabet]   \n",
       "382                                 [count of records]   \n",
       "101                                              [arc]   \n",
       "..                                                 ...   \n",
       "800                                 [show a pie chart]   \n",
       "71   [acc_home = \"7–1\" or team_name = \"Virginia Tech\"]   \n",
       "484                                      [time series]   \n",
       "457                                        [draw hist]   \n",
       "644                                                 []   \n",
       "\n",
       "                                                kwargs  \n",
       "708  {'x': 'name', 'filter': 'nationality = \"Canada...  \n",
       "434  {'y': 'count', 'where': 'competition_type = \"F...  \n",
       "460                                                 {}  \n",
       "382  {'cond': 'course_id >= 1 or+ course_id = 9 or ...  \n",
       "101  {'filter': 'all_games != \"28–6\" or all_games =...  \n",
       "..                                                 ...  \n",
       "800  {'when': 'school_id > 1', 'color': 'affiliatio...  \n",
       "71   {'chart': 'scatter', 'x': 'team id', 'y': 'all...  \n",
       "484  {'time': 'year', 'value': 'count', 'filter': '...  \n",
       "457  {'x_axis': 'all home', 'y_axis': 'mean team_id...  \n",
       "644  {'condition': 'first_year != \"2000\"', 'y_axis'...  \n",
       "\n",
       "[873 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insert_filter_to_vega_zero(\n",
    "    vega_zero: str,\n",
    "    filter_: str,\n",
    ") -> str:\n",
    "    vega_zero = VegaZero.parse(vega_zero)\n",
    "\n",
    "    if vega_zero.transform is not None:\n",
    "        transform = vega_zero.transform\n",
    "    else:\n",
    "        transform = VegaZeroTransform()\n",
    "\n",
    "    transform.filter = filter_\n",
    "\n",
    "    return str(vega_zero)\n",
    "\n",
    "\n",
    "def insert_filter_to_args_or_kwargs(\n",
    "    args: list, kwargs: dict, filter_arg: str, rand: Random\n",
    "):\n",
    "    use_kwarg = rand.random() < INSERT_FILTER_KWARG_FRAC\n",
    "\n",
    "    if use_kwarg:\n",
    "        kwargs = list(kwargs.items())\n",
    "\n",
    "        i = rand.randrange(len(kwargs) + 1)\n",
    "        k = rand.choice(FILTER_KEYWORDS)\n",
    "\n",
    "        kwargs.insert(i, (k, filter_arg))\n",
    "\n",
    "        kwargs = dict(kwargs)\n",
    "    else:\n",
    "        # Copy args to change the original argument (just in case)\n",
    "        args = [*args]\n",
    "\n",
    "        i = rand.randrange(len(args) + 1)\n",
    "\n",
    "        args.insert(i, filter_arg)\n",
    "\n",
    "    return args, kwargs\n",
    "\n",
    "\n",
    "def compose_single_filter(\n",
    "    column: str, dtype: Any, values: List[Any], rand: Random\n",
    ") -> Tuple[str, str]:\n",
    "    [val1, val2] = rand.choices(values, k=2)\n",
    "\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        patterns = INT_FILTER_PATTERNS\n",
    "\n",
    "        if val1 > val2:\n",
    "            val1, val2 = val2, val1\n",
    "\n",
    "    elif pd.api.types.is_string_dtype(dtype):\n",
    "        patterns = STR_FILTER_PATTERNS\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected dtype: {dtype}\")\n",
    "\n",
    "    vega_zero_pattern = rand.choice(list(patterns.keys()))\n",
    "    arg_pattern = rand.choice(patterns[vega_zero_pattern])\n",
    "\n",
    "    vega_zero = vega_zero_pattern.format(col=column, val1=val1, val2=val2)\n",
    "    arg = arg_pattern.format(col=column, val1=val1, val2=val2)\n",
    "\n",
    "    return vega_zero, arg\n",
    "\n",
    "\n",
    "def compose_filter(db_id: str, table: str, rand: Random) -> str:\n",
    "    n_filters = rand.choice([1, 2, 3])\n",
    "\n",
    "    candidates = rand.choices(COLUMN_CANDIDATES[(db_id, table)], k=n_filters)\n",
    "\n",
    "    filters = [\n",
    "        compose_single_filter(col, dtype, values, rand)\n",
    "        for col, dtype, values in candidates\n",
    "    ]\n",
    "\n",
    "    if n_filters == 1:\n",
    "        vega_zero_filter, arg = filters[0]\n",
    "    elif n_filters == 2:\n",
    "        vega_zero_filter = rand.choice(list(DOUBLE_FILTER_PATTERNS.keys()))\n",
    "        arg = rand.choice(DOUBLE_FILTER_PATTERNS[vega_zero_filter])\n",
    "\n",
    "        vega_zero_filter = vega_zero_filter.format(\n",
    "            cond1=filters[0][0], cond2=filters[1][0]\n",
    "        )\n",
    "        arg = arg.format(cond1=filters[0][1], cond2=filters[1][1])\n",
    "    else:\n",
    "        vega_zero_filter = rand.choice(list(TRIPLE_FILTER_PATTERNS.keys()))\n",
    "        arg = rand.choice(TRIPLE_FILTER_PATTERNS[vega_zero_filter])\n",
    "\n",
    "        vega_zero_filter = vega_zero_filter.format(\n",
    "            cond1=filters[0][0], cond2=filters[1][0], cond3=filters[2][0]\n",
    "        )\n",
    "        arg = arg.format(cond1=filters[0][1], cond2=filters[1][1], cond3=filters[2][0])\n",
    "\n",
    "    return vega_zero_filter, arg\n",
    "\n",
    "\n",
    "def augment_filter_data(df: pd.DataFrame, frac: float) -> pd.DataFrame:\n",
    "    rand = Random(RANDOM_SEED)\n",
    "\n",
    "    df = df[~df[\"vega_zero\"].str.contains(\" filter \")]\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.sample(frac=frac, replace=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # df.apply raises an error when frac is small and the number of rows is 0\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "\n",
    "    df[[\"_filter\", \"_arg\"]] = df[[\"db_id\", \"table\"]].apply(\n",
    "        lambda row: compose_filter(row[0], row[1], rand), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    df[\"vega_zero\"] = df[[\"vega_zero\", \"_filter\"]].apply(\n",
    "        lambda row: insert_filter_to_vega_zero(row[0], row[1]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df[[\"args\", \"kwargs\"]] = df[[\"args\", \"kwargs\", \"_filter\"]].apply(\n",
    "        lambda row: insert_filter_to_args_or_kwargs(\n",
    "            row[\"args\"], row[\"kwargs\"], row[\"_filter\"], rand\n",
    "        ),\n",
    "        axis=1,\n",
    "        result_type=\"expand\",\n",
    "    )\n",
    "\n",
    "    df = df.drop(columns=[\"_filter\", \"_arg\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "augmented_filter_train_df = augment_filter_data(train_df, INSERT_FILTER_FRAC)\n",
    "\n",
    "augmented_filter_train_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>table</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>args</th>\n",
       "      <th>kwargs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [db_id, table, chart, hardness, vega_zero, args, kwargs]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def augment_shuffled_data(\n",
    "    df: pd.DataFrame,\n",
    "    frac: float,\n",
    ") -> pd.DataFrame:\n",
    "    rand = Random(RANDOM_SEED)\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.sample(frac=frac, replace=True, random_state=RANDOM_SEED)\n",
    "    df[\"args\"] = df[\"args\"].apply(lambda args: rand.sample(args, len(args)))\n",
    "    df[\"kwargs\"] = df[\"kwargs\"].apply(\n",
    "        lambda kwargs: dict(rand.sample(list(kwargs.items()), len(kwargs)))\n",
    "    )\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "augmented_shuffle_train_df = augment_shuffled_data(train_df, SHUFFLE_FRAC)\n",
    "\n",
    "augmented_shuffle_train_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>table</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>args</th>\n",
       "      <th>kwargs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swimmer</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none id</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'x': 'name', 'filter': 'nationality = \"Canada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports_competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x competition_type y aggrega...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'y': 'count', 'where': 'competition_type = \"F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manufactory_1</td>\n",
       "      <td>products</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x name y aggregate count nam...</td>\n",
       "      <td>[count names, price &gt; 66, sort name in alphabet]</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e_learning</td>\n",
       "      <td>student_course_enrolment</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x date_of_completion y aggre...</td>\n",
       "      <td>[count of records]</td>\n",
       "      <td>{'cond': 'course_id &gt;= 1 or+ course_id = 9 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>arc</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark arc encoding x all_neutral y aggregate no...</td>\n",
       "      <td>[arc]</td>\n",
       "      <td>{'filter': 'all_games != \"28–6\" or all_games =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>university</td>\n",
       "      <td>arc</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark arc encoding x affiliation y aggregate su...</td>\n",
       "      <td>[show a pie chart]</td>\n",
       "      <td>{'when': 'school_id &gt; 1', 'color': 'affiliatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x team_id y aggregate none...</td>\n",
       "      <td>[acc_home = \"7–1\" or team_name = \"Virginia Tech\"]</td>\n",
       "      <td>{'chart': 'scatter', 'x': 'team id', 'y': 'all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>college_2</td>\n",
       "      <td>section</td>\n",
       "      <td>line</td>\n",
       "      <td>Hard</td>\n",
       "      <td>mark line encoding x year y aggregate count ye...</td>\n",
       "      <td>[time series]</td>\n",
       "      <td>{'time': 'year', 'value': 'count', 'filter': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>university_basketball</td>\n",
       "      <td>basketball_match</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x all_home y aggregate mean ...</td>\n",
       "      <td>[draw hist]</td>\n",
       "      <td>{'x_axis': 'all home', 'y_axis': 'mean team_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>party_host</td>\n",
       "      <td>party</td>\n",
       "      <td>bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x location y aggregate count...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'condition': 'first_year != \"2000\"', 'y_axis'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     db_id                     table  chart hardness  \\\n",
       "0                 swimming                   swimmer    bar     Easy   \n",
       "1       sports_competition               competition    bar   Medium   \n",
       "2            manufactory_1                  products    bar   Medium   \n",
       "3               e_learning  student_course_enrolment    bar   Medium   \n",
       "4    university_basketball          basketball_match    arc     Easy   \n",
       "..                     ...                       ...    ...      ...   \n",
       "868  university_basketball                university    arc     Easy   \n",
       "869  university_basketball          basketball_match  point     Easy   \n",
       "870              college_2                   section   line     Hard   \n",
       "871  university_basketball          basketball_match    bar   Medium   \n",
       "872             party_host                     party    bar   Medium   \n",
       "\n",
       "                                             vega_zero  \\\n",
       "0         mark bar encoding x name y aggregate none id   \n",
       "1    mark bar encoding x competition_type y aggrega...   \n",
       "2    mark bar encoding x name y aggregate count nam...   \n",
       "3    mark bar encoding x date_of_completion y aggre...   \n",
       "4    mark arc encoding x all_neutral y aggregate no...   \n",
       "..                                                 ...   \n",
       "868  mark arc encoding x affiliation y aggregate su...   \n",
       "869  mark point encoding x team_id y aggregate none...   \n",
       "870  mark line encoding x year y aggregate count ye...   \n",
       "871  mark bar encoding x all_home y aggregate mean ...   \n",
       "872  mark bar encoding x location y aggregate count...   \n",
       "\n",
       "                                                  args  \\\n",
       "0                                                   []   \n",
       "1                                                   []   \n",
       "2     [count names, price > 66, sort name in alphabet]   \n",
       "3                                   [count of records]   \n",
       "4                                                [arc]   \n",
       "..                                                 ...   \n",
       "868                                 [show a pie chart]   \n",
       "869  [acc_home = \"7–1\" or team_name = \"Virginia Tech\"]   \n",
       "870                                      [time series]   \n",
       "871                                        [draw hist]   \n",
       "872                                                 []   \n",
       "\n",
       "                                                kwargs  \n",
       "0    {'x': 'name', 'filter': 'nationality = \"Canada...  \n",
       "1    {'y': 'count', 'where': 'competition_type = \"F...  \n",
       "2                                                   {}  \n",
       "3    {'cond': 'course_id >= 1 or+ course_id = 9 or ...  \n",
       "4    {'filter': 'all_games != \"28–6\" or all_games =...  \n",
       "..                                                 ...  \n",
       "868  {'when': 'school_id > 1', 'color': 'affiliatio...  \n",
       "869  {'chart': 'scatter', 'x': 'team id', 'y': 'all...  \n",
       "870  {'time': 'year', 'value': 'count', 'filter': '...  \n",
       "871  {'x_axis': 'all home', 'y_axis': 'mean team_id...  \n",
       "872  {'condition': 'first_year != \"2000\"', 'y_axis'...  \n",
       "\n",
       "[873 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_df = pd.concat([augmented_filter_train_df, augmented_shuffle_train_df])\n",
    "\n",
    "augmented_train_df = augmented_train_df.reset_index(drop=True)\n",
    "augmented_train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={col: col.lower() for col in df.columns})\n",
    "\n",
    "    # The TAPEX tokenizer raises an error when the table contains non-str columns\n",
    "    df = df.astype(str)\n",
    "\n",
    "    for col_name, col_dtype in zip(df.columns, df.dtypes):\n",
    "        df[col_name] = df[col_name].str.lower()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functools.cache is supported in python3.9+, but use lru_cache to support python3.7+\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_and_preprocess_table(db_id: str, table_name: str) -> pd.DataFrame:\n",
    "    table = load_table(db_id, table_name)\n",
    "    table = preprocess_table(table)\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    table = load_and_preprocess_table(example[\"db_id\"], example[\"table\"])\n",
    "\n",
    "    query = example[\"query\"]\n",
    "    answer = example[\"vega_zero\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        table=table,\n",
    "        query=query,\n",
    "        answer=answer,\n",
    "        max_length=MAX_SOURCE_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        answer=answer,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(*args, **kwargs) -> str:\n",
    "    args = (str(arg) for arg in args)\n",
    "    args = \" [arg] \".join(args)\n",
    "    args = f\"[arg] {args}\"\n",
    "\n",
    "    kwargs = (f\"{k} [eq] {v}\" for k, v in kwargs.items())\n",
    "    kwargs = \" [kwarg] \".join(kwargs)\n",
    "    kwargs = f\"[kwarg] {kwargs}\"\n",
    "\n",
    "    return f\"{args} {kwargs}\".lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"query\"] = train_df.apply(\n",
    "    lambda row: preprocess_query(*row[\"args\"], **row[\"kwargs\"]), axis=1\n",
    ")\n",
    "\n",
    "if len(augmented_train_df) > 0:\n",
    "    augmented_train_df[\"query\"] = augmented_train_df.apply(\n",
    "        lambda row: preprocess_query(*row[\"args\"], **row[\"kwargs\"]), axis=1\n",
    "    )\n",
    "\n",
    "test_df[\"query\"] = test_df.apply(\n",
    "    lambda row: preprocess_query(*row[\"args\"], **row[\"kwargs\"]), axis=1\n",
    ")\n",
    "\n",
    "val_df[\"query\"] = val_df.apply(\n",
    "    lambda row: preprocess_query(*row[\"args\"], **row[\"kwargs\"]), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73853624c04147a8843dd524fe0b5868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100056e97516404783da79360951cba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ea02c8d4fb40db8ad2eefaafad945c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375cbc6ee40546a380d8bc506db6ff0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f848ceea82bc4003bb82a1eadd15fa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61befa27e17244e0b7bd547a2d818471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d101b6fcae470ab27503bdabbb3859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fe9f3a9f96433da221362a7608b8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4d044b62774498be91f250d793c531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/178 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbcbd04e2ab427f96bab659bcb4a5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/177 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bcde96257041e7bef642ed1da7b29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/177 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d41e947b4d84008aaec89c04a466fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/177 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4754593b1d524e3192e37c542c634059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1169735cb90e45d09be9512ee0d550b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f528b49c8440148731f4e8c424807e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b923ab0a694c8f912a9d3c96e07c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0cf6df632e4c8e8e617f479463c9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f122f13f63544bca8052c05c3039680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aec9e620554cedac59d4f03d626cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36d85acb0d14dbd9000e8647ccc1fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5e1028e03841549438e98d82c9915b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4b513e7a07438abd37c4281115ec23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531f922100ec4bd39d14eb03c72e5a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce0a0f7be064e53bb82ca4798d2c297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd1abf7d8d484f967596d7dc877210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5642b868e34b1a82d925754d4d3e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9491c4b81d8e4b6ebab84919a96b8839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87e10f2df3342d8852c85954efc2933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8020e69e7964b278f9ca292a9d8f905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9067e2d36034ea49be54bab23a69ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16eba551581b4a63b03cf3b30befaf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/23 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a3eaf90c934ee3a23189c0b4c93588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038d836514f3421f8ab187572a53a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14ae5e72ace46b8b389d0ffde1820a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40129810d97a44eabc27f25660b49b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00efa645dd9b444d970b5e3bf09c5558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/22 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2133\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'table', 'chart', 'hardness', 'vega_zero', 'query', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict()\n",
    "\n",
    "dataset[\"train\"] = Dataset.from_pandas(\n",
    "    pd.concat([train_df, augmented_train_df])\n",
    "    .reset_index(drop=True)\n",
    "    .drop(columns=[\"args\", \"kwargs\"])\n",
    ")\n",
    "dataset[\"test\"] = Dataset.from_pandas(test_df.drop(columns=[\"args\", \"kwargs\"]))\n",
    "dataset[\"validation\"] = Dataset.from_pandas(val_df.drop(columns=[\"args\", \"kwargs\"]))\n",
    "\n",
    "dataset = dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=False,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    ")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102ffb4956c541138716900bf8675200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return exact_match.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=Seq2SeqTrainingArguments(\n",
    "        output_dir=MODEL_OUTPUT_DIR,\n",
    "        predict_with_generate=True,\n",
    "        num_train_epochs=50,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=True,\n",
    "        metric_for_best_model=\"exact_match\",\n",
    "        push_to_hub=push_model_to_huggingface_hub,\n",
    "        report_to=\"wandb\" if report_to_wandb else \"none\",\n",
    "    ),\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=5),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/jupyter/vxnli/.venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2183\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13650\n",
      "  Number of trainable parameters = 139422720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3822' max='13650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3822/13650 22:19 < 57:27, 2.85 it/s, Epoch 14/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.318852</td>\n",
       "      <td>0.418519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.302561</td>\n",
       "      <td>0.455556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.337232</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.329871</td>\n",
       "      <td>0.574074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.319890</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.362631</td>\n",
       "      <td>0.540741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>0.562963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.374550</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.413344</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.421912</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.365395</td>\n",
       "      <td>0.585185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.398875</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.399365</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-273\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-273/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-273/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-273/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-273/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-273/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-546\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-546/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-546/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-546/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-546/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-546/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-273] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-819\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-819/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-819/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-819/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-819/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-819/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-546] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-1092\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-1092/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-1092/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-1092/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1092/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1092/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-819] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-1365\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-1365/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-1365/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-1365/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1365/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1365/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-1638\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-1638/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-1638/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-1638/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1638/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1638/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-1365] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-1911\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-1911/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-1911/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-1911/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1911/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-1911/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-1638] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-2184\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-2184/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-2184/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-2184/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2184/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2184/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-1911] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-2457\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-2457/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-2457/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-2457/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2457/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2457/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-1092] due to args.save_total_limit\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-2184] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-2730\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-2730/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-2730/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-2730/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2730/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-2730/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-3003\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-3003/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-3003/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-3003/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3003/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3003/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-2730] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-3276\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-3276/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-3276/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-3276/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3276/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3276/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-3003] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-3549\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-3549/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-3549/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-3549/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3549/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3549/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-3276] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/models/vxnli-v2beta10/checkpoint-3822\n",
      "Configuration saved in ../data/models/vxnli-v2beta10/checkpoint-3822/config.json\n",
      "Model weights saved in ../data/models/vxnli-v2beta10/checkpoint-3822/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/vxnli-v2beta10/checkpoint-3822/tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3822/special_tokens_map.json\n",
      "added tokens file saved in ../data/models/vxnli-v2beta10/checkpoint-3822/added_tokens.json\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-3549] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/models/vxnli-v2beta10/checkpoint-2457 (score: 0.5925925925925926).\n",
      "Deleting older checkpoint [../data/models/vxnli-v2beta10/checkpoint-3822] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3822, training_loss=0.04471869168638372, metrics={'train_runtime': 1340.9279, 'train_samples_per_second': 81.399, 'train_steps_per_second': 10.18, 'total_flos': 1.579095420005376e+16, 'train_loss': 0.04471869168638372, 'epoch': 14.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.42609551548957825,\n",
       " 'eval_exact_match': 0.5518518518518518,\n",
       " 'eval_runtime': 24.0048,\n",
       " 'eval_samples_per_second': 11.248,\n",
       " 'eval_steps_per_second': 1.416,\n",
       " 'epoch': 14.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate must be called for the model card\n",
    "\n",
    "trainer.evaluate(dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ds: Dataset) -> List[str]:\n",
    "    preds = trainer.predict(\n",
    "        ds,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "    )\n",
    "\n",
    "    preds = tokenizer.batch_decode(\n",
    "        preds.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    return [pred.strip() for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: chart, db_id, vega_zero, query, hardness, table. If chart, db_id, vega_zero, query, hardness, table are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x'],\n",
       " ['mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark bar encoding x name y aggregate none weight transform sort x asc',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x',\n",
       "  'mark point encoding x investor_id y aggregate mean share_count transform group x'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(dataset[\"test\"])\n",
    "\n",
    "preds[:5], dataset[\"test\"][\"vega_zero\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.5481481481481482}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match.compute(\n",
    "    predictions=preds,\n",
    "    references=dataset[\"test\"][\"vega_zero\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>table</th>\n",
       "      <th>chart</th>\n",
       "      <th>hardness</th>\n",
       "      <th>vega_zero</th>\n",
       "      <th>query</th>\n",
       "      <th>pred</th>\n",
       "      <th>exact_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg]  [kwarg] use_bar_chart [eq] true [kwarg]...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg] use a bar chart [kwarg] x [eq] name [kwa...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>people</td>\n",
       "      <td>bar</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>[arg]  [kwarg] graph [eq] bar [kwarg] x [eq] n...</td>\n",
       "      <td>mark bar encoding x name y aggregate none weig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>[arg] scatter chart [arg] investor id and mean...</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>point</td>\n",
       "      <td>Easy</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>[arg]  [kwarg] graph_type [eq] scatter [kwarg]...</td>\n",
       "      <td>mark point encoding x investor_id y aggregate ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>Line</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark line encoding x date_of_transaction y agg...</td>\n",
       "      <td>[arg]  [kwarg] time_axis [eq] date_of_transact...</td>\n",
       "      <td>mark line encoding x date_of_transaction y agg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tracking_share_transactions</td>\n",
       "      <td>transactions</td>\n",
       "      <td>Line</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark line encoding x date_of_transaction y agg...</td>\n",
       "      <td>[arg] show me a trend [kwarg] x [eq] date_of_t...</td>\n",
       "      <td>mark line encoding x date_of_transaction y agg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>financial_transactions</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>[arg] show the transaction types and the total...</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>financial_transactions</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>[arg]  [kwarg] x [eq] type [kwarg] y [eq] amou...</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>customers_and_invoices</td>\n",
       "      <td>financial_transactions</td>\n",
       "      <td>Bar</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>[arg] ['transaction_type', 'sum(transaction_am...</td>\n",
       "      <td>mark bar encoding x transaction_type y aggrega...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           db_id                   table  chart hardness  \\\n",
       "0                 candidate_poll                  people    bar     Easy   \n",
       "1                 candidate_poll                  people    bar     Easy   \n",
       "2                 candidate_poll                  people    bar     Easy   \n",
       "3    tracking_share_transactions            transactions  point     Easy   \n",
       "4    tracking_share_transactions            transactions  point     Easy   \n",
       "..                           ...                     ...    ...      ...   \n",
       "265  tracking_share_transactions            transactions   Line   Medium   \n",
       "266  tracking_share_transactions            transactions   Line   Medium   \n",
       "267       customers_and_invoices  financial_transactions    Bar   Medium   \n",
       "268       customers_and_invoices  financial_transactions    Bar   Medium   \n",
       "269       customers_and_invoices  financial_transactions    Bar   Medium   \n",
       "\n",
       "                                             vega_zero  \\\n",
       "0    mark bar encoding x name y aggregate none weig...   \n",
       "1    mark bar encoding x name y aggregate none weig...   \n",
       "2    mark bar encoding x name y aggregate none weig...   \n",
       "3    mark point encoding x investor_id y aggregate ...   \n",
       "4    mark point encoding x investor_id y aggregate ...   \n",
       "..                                                 ...   \n",
       "265  mark line encoding x date_of_transaction y agg...   \n",
       "266  mark line encoding x date_of_transaction y agg...   \n",
       "267  mark bar encoding x transaction_type y aggrega...   \n",
       "268  mark bar encoding x transaction_type y aggrega...   \n",
       "269  mark bar encoding x transaction_type y aggrega...   \n",
       "\n",
       "                                                 query  \\\n",
       "0    [arg]  [kwarg] use_bar_chart [eq] true [kwarg]...   \n",
       "1    [arg] use a bar chart [kwarg] x [eq] name [kwa...   \n",
       "2    [arg]  [kwarg] graph [eq] bar [kwarg] x [eq] n...   \n",
       "3    [arg] scatter chart [arg] investor id and mean...   \n",
       "4    [arg]  [kwarg] graph_type [eq] scatter [kwarg]...   \n",
       "..                                                 ...   \n",
       "265  [arg]  [kwarg] time_axis [eq] date_of_transact...   \n",
       "266  [arg] show me a trend [kwarg] x [eq] date_of_t...   \n",
       "267  [arg] show the transaction types and the total...   \n",
       "268  [arg]  [kwarg] x [eq] type [kwarg] y [eq] amou...   \n",
       "269  [arg] ['transaction_type', 'sum(transaction_am...   \n",
       "\n",
       "                                                  pred  exact_matched  \n",
       "0    mark bar encoding x name y aggregate none weig...           True  \n",
       "1    mark bar encoding x name y aggregate none weig...           True  \n",
       "2    mark bar encoding x name y aggregate none weig...           True  \n",
       "3    mark point encoding x investor_id y aggregate ...           True  \n",
       "4    mark point encoding x investor_id y aggregate ...           True  \n",
       "..                                                 ...            ...  \n",
       "265  mark line encoding x date_of_transaction y agg...          False  \n",
       "266  mark line encoding x date_of_transaction y agg...           True  \n",
       "267  mark bar encoding x transaction_type y aggrega...          False  \n",
       "268  mark bar encoding x transaction_type y aggrega...           True  \n",
       "269  mark bar encoding x transaction_type y aggrega...          False  \n",
       "\n",
       "[270 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = dataset[\"test\"].to_pandas()\n",
    "preds_df = preds_df.drop(columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "preds_df[\"pred\"] = preds\n",
    "preds_df[\"exact_matched\"] = preds_df[\"pred\"] == preds_df[\"vega_zero\"]\n",
    "\n",
    "preds_df.to_csv(RESULT_OUTPUT_DIR.joinpath(\"prediction.csv\"))\n",
    "\n",
    "preds_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if report_to_wandb:\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if push_model_to_huggingface_hub:\n",
    "    trainer.push_to_hub()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63d5e78cacc7bbb3aa8f0f1cd8b8015c0d580cb8c6884f2092d527cf506d691b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
